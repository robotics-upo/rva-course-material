{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deploying-imageclassification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMOaCZFrLqbNImnkz+6yPWR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robotics-upo/rva-course-material/blob/master/deeplearningbasics/deploying_imageclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q49tF4sm2J4L"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjS9FyyX2NNc"
      },
      "source": [
        "In this part, we will see how to use a model already trained in our code with OpenCV.\n",
        "\n",
        "We will use it to detect objects from the CIFAR categories in images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKongL6FizI"
      },
      "source": [
        "# Loading data and models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDzuvSKWFSCw"
      },
      "source": [
        "Let's load the model we trained in the previous session from file. We use in the virtual machine the Google Drive, which is mounted.\n",
        "\n",
        "You can load the models and files from your local folders if you are not using Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPwzc8rJE5dk"
      },
      "source": [
        "#Numpy module\n",
        "import numpy as np\n",
        "\n",
        "#Import OpenCV\n",
        "import cv2\n",
        "#Import tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "#We can use OpenCV in Colab, but not its functions for creating plots\n",
        "#We use matplotlib for generating plots\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "#We use the library scikit to read images from url \n",
        "#In OpenCV, the function to read from file is cv2.imread\n",
        "from skimage import io\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvnSxf6Z4YqI"
      },
      "source": [
        "#Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cspwphInG3Rb"
      },
      "source": [
        "I am assuming you have a folder called **colabfiles** in your Google Drive **root** folder. \n",
        "\n",
        "Within the folder, we have the model **classif.h5**.\n",
        "\n",
        "If the folders and files are called differently, change the paths and names.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZLavo8LG099"
      },
      "source": [
        "#Let's load the CNN model using the Keras API\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/My Drive/colabfiles/classif.h5')\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKIta01dKnnv"
      },
      "source": [
        "Load the image and show it. Matplotlib assumes that images are RGB, and OpenCV stores them as BGR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2WYF4_DHAJY"
      },
      "source": [
        "\n",
        "#Unmount the drive if we are not using it more\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "#Let's load an image\n",
        "imrgb = io.imread('https://robotics.upo.es/~lmercab/rva/test.jpg')\n",
        "\n",
        "#We can use OpenCV in Colab, but not its function imshow\n",
        "#We use matplotlib instead\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(imrgb, cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrroiLDLajqP"
      },
      "source": [
        "# Using our CNN for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f4eryXIK673"
      },
      "source": [
        "We can process patches through our network. Recall our network receives as inputs 32x32 images (normalized between 0 and 1) and outputs probabilities for each of the 10 classes of CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcIIGVbuK91v"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "cifar10_labels = ['airplane', 'automobile', 'bird','cat','deer','dog','frog'\n",
        "'horse','ship', 'truck']\n",
        "\n",
        "#32x32 image patch, normalized\n",
        "im_patch = imrgb[150:150+32,100:100+32]/255.0\n",
        "plt.imshow(im_patch, cmap=plt.cm.binary)\n",
        "\n",
        "#The network expect as inputs sets of images. We have to expand the dimension of\n",
        "#the image\n",
        "im_patch_final = np.expand_dims(im_patch, 0)\n",
        "\n",
        "prediction = model.predict(im_patch_final)\n",
        "print(prediction)\n",
        "\n",
        "print(\"PredicciÃ³n del modelo: \", cifar10_labels[np.argmax(prediction[0])] )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjiQ4qlzavqh"
      },
      "source": [
        "We can use our trained network to look for cars in the image. Also, we want to detect multiple cars, not only one.\n",
        "\n",
        "The idea is to cover the whole image, extracting patches of 32x32 and taking those ones in which the network predicts and automobile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RHNDHPCRsmq"
      },
      "source": [
        "#Loop over the image looking for cars\n",
        "#We extract 32x32 patches each time\n",
        "im_result = imrgb.copy()\n",
        "for r in range(0,imrgb.shape[0] - 32, 32):\n",
        "  for c in range(0,imrgb.shape[1] - 32, 32):\n",
        "    im_patch_final = np.expand_dims(imrgb[r:r+32,c:c+32], 0)/255.0\n",
        "    prediction = model.predict(im_patch_final)\n",
        "    #Draw a rectangle on the original image if the probability of car is over 0.5\n",
        "    if(np.argmax(prediction[0]) == 1 and prediction[0][1]>0.5):\n",
        "      upper_left = (c, r)\n",
        "      bottom_right = (c + 32, r+32)\n",
        "      cv2.rectangle(im_result,upper_left, bottom_right, (255,0,0), 2)\n",
        "     \n",
        "plt.imshow(im_result, cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPG_23CXbfTf"
      },
      "source": [
        "# Searching at different scales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Ct1f_6bknl"
      },
      "source": [
        "The main problem is that our network expects cars as 32x32 patches. Of course, in our image there are cars larger than that. \n",
        "\n",
        "We need to search for cars in multiple scales in the image. For that, we can use image pyramids.\n",
        "\n",
        "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_pyramids/py_pyramids.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6wmUffwV_ij"
      },
      "source": [
        "#Create an image pyramid\n",
        "\n",
        "#Dowsample image by 2\n",
        "imrgb_2 = cv2.pyrDown(imrgb)\n",
        "plt.imshow(imrgb_2, cmap=plt.cm.binary)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZhoG7ACWqIy"
      },
      "source": [
        "#Downsample the former by 2 (so the original by 4)\n",
        "imrgb_4 = cv2.pyrDown(imrgb_2)\n",
        "plt.imshow(imrgb_4, cmap=plt.cm.binary)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWA1C3VHW6ed"
      },
      "source": [
        "#Search in downsampled images\n",
        "\n",
        "#im_result_4 = imrgb_4.copy()\n",
        "for r in range(0,imrgb_4.shape[0] - 32, 8):\n",
        "  for c in range(0,imrgb_4.shape[1] - 32, 8):\n",
        "    im_patch_final = np.expand_dims(imrgb_4[r:r+32,c:c+32], 0)/255.0\n",
        "    prediction = model.predict(im_patch_final)\n",
        "    #Draw a rectangle on the original image if the probability of car is over 0.5\n",
        "    if(np.argmax(prediction[0]) == 1 and prediction[0][1]>0.5):\n",
        "      upper_left = (c*4, r*4)\n",
        "      bottom_right = (c*4 + 32*4, r*4+32*4)\n",
        "      cv2.rectangle(im_result,upper_left, bottom_right, (0,255,0), 2)\n",
        "\n",
        "for r in range(0,imrgb_2.shape[0] - 32, 8):\n",
        "  for c in range(0,imrgb_2.shape[1] - 32, 8):\n",
        "    im_patch_final = np.expand_dims(imrgb_2[r:r+32,c:c+32], 0)/255.0\n",
        "    prediction = model.predict(im_patch_final)\n",
        "    #Draw a rectangle on the original image if the probability of car is over 0.5\n",
        "    if(np.argmax(prediction[0]) == 1 and prediction[0][1]>0.5):\n",
        "      upper_left = (c*2, r*2)\n",
        "      bottom_right = (c*2 + 32*2, r*2+32*2)\n",
        "      cv2.rectangle(im_result,upper_left, bottom_right, (0,0,255), 2)\n",
        "     \n",
        "plt.imshow(im_result, cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nI8JTiv3hLo"
      },
      "source": [
        "#Using pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GXkFUOh3l1s"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "classifier_model =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "classifier = tf.keras.Sequential([\n",
        "    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n",
        "])\n",
        "\n",
        "print(classifier.summary)\n",
        "\n",
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOcUrMiM39So"
      },
      "source": [
        "im_input = io.imread('https://robotics.upo.es/~lmercab/rva/bookshelf.jpg')\n",
        "\n",
        "im_input = im_input/255.0\n",
        "print(im_input.shape)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(im_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScRpTyv64Nbj"
      },
      "source": [
        "res = tf.image.resize(im_input, IMAGE_SHAPE)\n",
        "\n",
        "print(res.shape)\n",
        "\n",
        "result = classifier.predict(res[np.newaxis, ...])\n",
        "print(result.shape)\n",
        "\n",
        "predicted_class = np.argmax(result[0], axis=-1)\n",
        "print(predicted_class)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMRFuDHV4sHf"
      },
      "source": [
        "plt.figure()  \n",
        "plt.imshow(res)\n",
        "plt.axis('off')\n",
        "predicted_class_name = imagenet_labels[predicted_class]\n",
        "_ = plt.title(\"Prediction: \" + predicted_class_name.title())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdbXGPXD7lGs"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Load train dataset for CIFAR10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(x_test[100], cmap=plt.cm.binary)\n",
        "\n",
        "#Normalize data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtU31Emv70YF"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", output_shape=[1280],\n",
        "                   trainable=False),  # Can be True.\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.build([None, 224, 224, 3])  # Batch input shape.\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXXacEeA8qsK"
      },
      "source": [
        "x_resized = tf.image.resize(x_train[0:10000,:,:,:], IMAGE_SHAPE)\n",
        "\n",
        "print(x_resized.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aETNCGm28MSE"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "_ = model.fit(x_resized, y_train[0:10000,:], epochs=10, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvm9TOi28OT_"
      },
      "source": [
        "x_resized = tf.image.resize(x_test[2000:3000,:,:,:], IMAGE_SHAPE)\n",
        "\n",
        "_ , test_acc = model.evaluate(x_resized, y_test[2000:3000,:])\n",
        "\n",
        "print('Accuracy:', test_acc*100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}