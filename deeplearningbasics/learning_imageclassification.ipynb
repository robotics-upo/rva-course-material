{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learning-imageclassification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPMqmyj9SUQ2IqeG8SGap1i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robotics-upo/rva-course-material/blob/master/deeplearningbasics/learning_imageclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJjGdFqaYtjT"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this session we will learn to create and train a simple network for **image classification**.\n",
        "\n",
        "We will be using the following tools:  TensorFlow and its Keras API. \n",
        "\n",
        "* **TensorFlow**: open source library for machine learning \n",
        " * https://www.tensorflow.org/\n",
        " * https://www.tensorflow.org/guide\n",
        "\n",
        "* **Keras** high-level API for TensorFlow: \n",
        " * https://keras.io/\n",
        " * https://www.tensorflow.org/api_docs/python/tf/keras \n",
        "\n",
        "TensorFlow comes preinstalled in the Colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZutggoEPmLba"
      },
      "source": [
        "# Loading data\n",
        "\n",
        "One fundamental aspect for learning networks for CV application is to have data to learn from.\n",
        "\n",
        "The Keras API allows to access publicly available datasets in a very simple way. \n",
        "\n",
        "* https://keras.io/datasets/\n",
        "\n",
        "For training this application and example, we will be using data from the **CIFAR dataset**\n",
        "\n",
        "* https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "With the next lines, we load the data we will use and show one exemplar image from the dataset. We can use OpenCV in Colab, but not the GUI functions. So we will use the plotting facilities of **matplotlib**:\n",
        "\n",
        "* https://matplotlib.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwPF_AnkmFGT"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Load train dataset for CIFAR10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "#Check the shape of the data\n",
        "print('Input shape for the train set', x_train.shape)\n",
        "print('Label shape for the train set',y_train.shape)\n",
        "print('Input shape for the test set',x_test.shape)\n",
        "print('Label shape for the test set', y_test.shape)\n",
        "\n",
        "#Show one sample image (image 100 from the dataset)\n",
        "#We can use OpenCV in Colab, but not its function imshow\n",
        "#We use matplotlib instead\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(x_test[100], cmap=plt.cm.binary)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W6zlhxBHrFF"
      },
      "source": [
        "## Preparing the data\n",
        "We will prepare the data for training. First, we normalize the data. Instead of pixel values between 0 and 255, we normalize them between 0 and 1.\n",
        "\n",
        "Then, the labels from CIFAR-10 store the class of each image (as a number between 0 and 9). We will convert this to a categorical vector that just has 10 elements (corresponding to the 10 classes) and a 1 in the corresponding class, 0 in the rest of elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40uwCHstINux"
      },
      "source": [
        "#Normalize data. Instead of pixel values between 0 and 255, we normalize them\n",
        "#between 0 and 1\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "#Print label for image 100\n",
        "print('Label for Image 100:', y_train[100])\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "print('New shape for labels', y_train.shape)\n",
        "print('Label for Image 100 as categorical vector',y_train[100])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnl2Hz1nq3oU"
      },
      "source": [
        "# Creating our CNN\n",
        "\n",
        "The next lines create a simple network with several convolutional and maxpool layers, followed by fully connected layers, stacked in a sequential way for classification.\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "* https://www.tensorflow.org/guide/keras/sequential_model\n",
        "\n",
        "This network is similar (but with less convolutional layers) than the one described in:\n",
        "\n",
        "* https://poloclub.github.io/cnn-explainer/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff5Qsufnra3r"
      },
      "source": [
        "#Simple sequential model\n",
        "model = tf.keras.Sequential()\n",
        "#First layer is a convolutional layer with 32 channels (filters), followed\n",
        "#by ReLU activations\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "#We add a MaxPooling layer, reducing the resolution\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#New convolutional layer with 64 channels (filters), followed by ReLU\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "#Again MaxPooling layer, reducing the resolution\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Convert the output to a vector\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Add a fully connected layer with ReLU activation\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "\n",
        "#Output layer: fully connected. The number of neurons should match the number of\n",
        "#classes \n",
        "#The output is converted to probabilities using softmax activation\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3FvxXyVuhLL"
      },
      "source": [
        "# Training\n",
        "\n",
        "The next lines allow to train the model using the data from CIFAR-10 downloaded above.\n",
        "\n",
        "The important aspects are the **loss function** employed, and the **optimizer**. The function `compile` allows also to provide **metrics** to monitor the performance.\n",
        "\n",
        "\n",
        "* https://keras.io/api/losses/\n",
        "* https://keras.io/api/metrics/\n",
        "* https://keras.io/api/optimizers/\n",
        "\n",
        "More information:\n",
        "\n",
        "* https://keras.io/api/models/model_training_apis/\n",
        "* https://www.tensorflow.org/guide/keras/train_and_evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxQ4UiVQujSp"
      },
      "source": [
        "#Configure the training\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "#Train the model using the training set.\n",
        "_ = model.fit(x_train, y_train, epochs=10, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGmPaSH_NE-O"
      },
      "source": [
        "The former process iterate over all training data. In each epoch, different interations of the optimizer are performed (in this case, SGD).\n",
        "There are several parameters that can be controlled (if they are not set, they are estabilished to default values).\n",
        "\n",
        "Two important ones are the following:\n",
        "\n",
        "* **batch_size** (defaults to 32): In each epoch, the training data is divided in batches of this size. Each batch is used to estimate the gradient for the optimizer and perform one iteration. In each epoch, the set of batches is iterated. In general terms, larger values take longer times per iteration/step (but there are less steps per epoch). Larger sizes can lead to poor gradient estimations. Too short sizes can lead to very noisy gradients.\n",
        " * https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/\n",
        "* **validation_split** (defaults to 0): Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. This is useful to see if overfitting is happening, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TemId90yNYiJ"
      },
      "source": [
        "_ = model.fit(x_train, y_train, batch_size=64, validation_split=0.1,epochs=10, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Y-oUXR6hKl"
      },
      "source": [
        "# Evaluation\n",
        "Let's check the accuracy for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nms5SjKCwZMd"
      },
      "source": [
        "\n",
        "test_loss , test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Loss:', test_loss)\n",
        "print('Accuracy:', test_acc*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I02ywLH7Fcr"
      },
      "source": [
        "You can enhance the accuracy by adapting learning parameters (training the model longer, etc), adding more data (we are using already all images from CIFAR-10) and playing with the network architecture (complexity, layers, etc).\n",
        "\n",
        "You can check the current accuracy that it is achieved in this benchmark at:\n",
        "\n",
        "https://benchmarks.ai/cifar-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyNWLT4ktWcO"
      },
      "source": [
        "#Homework #1\n",
        "\n",
        "Modify the network (changing the architecture) and training parameters to achieve **at least an accuracy of 75%** in the **test set**.\n",
        "\n",
        "Consider longer periods for training and additional layers. Search for information about and include **dropout** layers to reduce overfitting \n",
        " * https://keras.io/api/layers/regularization_layers/dropout/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xskPn3GgwESq"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bav7hkZiiX7d"
      },
      "source": [
        "Once our network is trained, it can be used to infer the category of an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm9Dg_MrwGHH"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "cifar10_labels = ['airplane', 'automobile', 'bird','cat','deer','dog','frog',\n",
        "'horse','ship', 'truck']\n",
        "\n",
        "prediction = model.predict(x_test)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(x_test[100], cmap=plt.cm.binary)\n",
        "\n",
        "print(prediction[100])\n",
        "print(\"Predicci贸n del modelo: \", np.argmax(prediction[100]) )\n",
        "print(\"Predicci贸n del modelo: \", cifar10_labels[np.argmax(prediction[100])] )\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(x_test[350], cmap=plt.cm.binary)\n",
        "\n",
        "print(prediction[350])\n",
        "print(\"Predicci贸n del modelo: \", np.argmax(prediction[350]) )\n",
        "print(\"Predicci贸n del modelo: \", cifar10_labels[np.argmax(prediction[350])] )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwy3WXaj9omH"
      },
      "source": [
        "# Storing the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9ao3vqE9yPc"
      },
      "source": [
        "We will store the network weights for future use. In this example, we will store it in Google Drive, but you can use the same functions to save the model locally.\n",
        "\n",
        "The My Drive from Google Drive is mounted at the location /content/drive of the Colab Virtual Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNiv4SVt9854"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjnCvPkX_ZzY"
      },
      "source": [
        "We are goint to save the whole model. That is, the model and the resultant weights. There are other options, like saving only the weights\n",
        "\n",
        "https://www.tensorflow.org/guide/keras/save_and_serialize?hl=es\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMm-fGwJ-i3a"
      },
      "source": [
        "model.save('/content/drive/My Drive/colabfiles/classif.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWe9gQbfEDfm"
      },
      "source": [
        "We unmount the drive. \n",
        "\n",
        "Again, these lines are not needed if you use this code locally\n",
        "\n",
        "We will learn how to use the stored model in next sessions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqmEd0nIAm3Q"
      },
      "source": [
        "%ls '/content/drive/My Drive/colabfiles/'\n",
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNeCoQcPuV4a"
      },
      "source": [
        "#Tutorials\n",
        "\n",
        "* Classification: https://www.tensorflow.org/tutorials/keras/classification\n"
      ]
    }
  ]
}