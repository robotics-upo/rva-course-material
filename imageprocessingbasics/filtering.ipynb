{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "filtering.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2284TaPBhgTM2hOHk3iE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robotics-upo/rva-course-material/blob/master/imageprocessingbasics/filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0f230XxjCmZ"
      },
      "source": [
        "# Linear Filtering in OpenCV\n",
        "\n",
        "In this lab session we will use the following tools:\n",
        "\n",
        "*   **OpenCV**: http://opencv.org\n",
        "*   **Numpy**, for handling multidimensional arrays (like images): https://numpy.org/\n",
        "*   **Matplotlib**, library for visualization in python: https://matplotlib.org/\n",
        "\n",
        "We will use the 3.x version of OpenCVâ€™s API. We will intensively refer to the documentation (https://opencv-python-tutroals.readthedocs.io/en/latest/index.html)\n",
        "\n",
        "We analyze the linear filtering operations in OpenCV and use them to extract features of interest like borders and points\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYTNL2u9i67O"
      },
      "source": [
        "#OpenCV module\n",
        "import cv2\n",
        "\n",
        "#Numpy module\n",
        "import numpy as np\n",
        "\n",
        "#We can use OpenCV in Colab, but not its functions for creating plots\n",
        "#We use matplotlib for generating plots\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#We use the library scikit to read images from url \n",
        "#In OpenCV, the function to read from file is cv2.imread\n",
        "from skimage import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvx6yyNajxko"
      },
      "source": [
        "\n",
        "As seen in the slides, one very common region-based operation is filtering. \n",
        "\n",
        "Linear filters operate by convolving a **kernel** with the image.\n",
        "\n",
        "* 2D linear filters, convolutions: \n",
        "  * https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html\n",
        "\n",
        "We will be using some simple kernels to extract borders in the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yybQAR_jfCx"
      },
      "source": [
        "im = io.imread('https://robotics.upo.es/~lmercab/rva/background.jpg')\n",
        "\n",
        "plt.figure()  \n",
        "plt.imshow(im)\n",
        "\n",
        "#Kernel for edge detection\n",
        "filter_kernel = np.array([[-1,-2,-1],\n",
        "\t\t\t\t[0,0,0],\n",
        "\t\t\t\t[1,2,1]])\n",
        "\n",
        "print(filter_kernel)\n",
        "\n",
        "#Apply filter over the blue channel. -1 indicates that the pixel type in the output is the same\n",
        "#as the input (in this case, uint8)\n",
        "h_edges = cv2.filter2D(im[:,:,0],-1,filter_kernel)\n",
        "\n",
        "#Type of pixels\n",
        "print(h_edges.dtype)\n",
        "\n",
        "plt.figure()  \n",
        "plt.imshow(h_edges,cmap=plt.cm.gray)\n",
        "plt.title('Filtered')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7VRdM_Qk7j3"
      },
      "source": [
        "Now we have to be careful with the types of the images. Filtering operations will lead to outputs that typically are real numbers, while the pixels in the original image in this case are coded as `uint8`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWbdY8rDlL_g"
      },
      "source": [
        "#The problem with the former case is that, as the output is uint8, negative numbers\n",
        "#are truncated to 0. That is edges from bright to dark do not appear\n",
        "#Alternatively, we can store the output as floats\t\n",
        "h_edges_2 = cv2.filter2D(im[:,:,0],cv2.CV_64F,filter_kernel)\n",
        "\n",
        "#Type of pixels\n",
        "print(h_edges_2.dtype)\n",
        "\n",
        "#Get now the absolute value\n",
        "abs_h_edges64f = np.absolute(h_edges_2)\n",
        "\n",
        "#Check the difference\n",
        "plt.figure()  \n",
        "plt.imshow(abs_h_edges64f,cmap=plt.cm.gray)\n",
        "plt.title('Filtered')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W3Y0pGFl5u9"
      },
      "source": [
        "The kernels are also numpy arrays.\n",
        "\n",
        "By transposing the former kernel, we obtain a filter that \"responds\" vertical edges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXIVQebalxJ0"
      },
      "source": [
        "#Same as above\n",
        "v_edges_2 = cv2.filter2D(im[:,:,0],cv2.CV_64F,np.transpose(filter_kernel))\n",
        "abs_v_edges64f = np.absolute(v_edges_2)\n",
        "\n",
        "plt.figure()  \n",
        "plt.imshow(abs_v_edges64f,cmap=plt.cm.gray)\n",
        "plt.title('Vertical edges kernel')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzXEQzw2uKLJ"
      },
      "source": [
        "# Homework #1\n",
        "\n",
        "Play with the thresholds and add binary operations to obtain a clean binary edge image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_JEA1tLme1r"
      },
      "source": [
        "#We can add the outputs to obtain an image\n",
        "#with the response of both filters (in this case, the absolute value)\n",
        "abs_edges_64f = abs_v_edges64f + abs_h_edges64f\n",
        "\n",
        "plt.figure()  \n",
        "plt.imshow(abs_edges_64f,cmap=plt.cm.gray)\n",
        "plt.title('Edge response')\n",
        "\n",
        "#Check the values of abs_edges_f64. They not need to be between 0 and 255\n",
        "print('Maximum', np.max(abs_edges_64f))\n",
        "print('Minimum', np.min(abs_edges_64f))\n",
        "\n",
        "\n",
        "#We can apply the threshold operation to extract the stongest responses\n",
        "ret,binary_edges = cv2.threshold(abs_edges_64f,100,255,cv2.THRESH_BINARY)\n",
        "\n",
        "plt.figure()  \n",
        "plt.imshow(binary_edges,cmap=plt.cm.gray)\n",
        "plt.title('Binarized edges ')\n",
        "\n",
        "print(binary_edges.dtype)\n",
        "print('Maximum', np.max(binary_edges))\n",
        "print('Minimum', np.min(binary_edges))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9FKoP9woJFQ"
      },
      "source": [
        "# Smoothing filters\n",
        "\n",
        "One filter that is used typically to remove noise is an smoothing filter.\n",
        "\n",
        "An smoothing filter averages the region surrounding the pixel of interest.\n",
        "\n",
        "If we want to give more importance to zones closer to the pixel, typicall a Gaussian kernel is used (the Gaussian kernel has many nice properties as well, but we will not see them now)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgJxS0rxoMG7"
      },
      "source": [
        "#Create a Gaussian kernel\n",
        "#Size\n",
        "k=10\n",
        "#Sigma\n",
        "sigma=5\n",
        "\n",
        "gaussKernel=np.zeros(shape=(k,k))\n",
        "\n",
        "#Apply the Gaussian 'bell' equation\n",
        "for i in range(k):\n",
        "  for j in range(k):\n",
        "    gaussKernel[i,j] = np.exp(-((i-(k-1)/2)**2+(j-(k-1)/2)**2)/sigma**2)\n",
        "\n",
        "#Normalize the kernel (so all element sum 1.0)\n",
        "gaussKernel /= np.sum(gaussKernel)\n",
        "\n",
        "plt.figure()  \n",
        "plt.imshow(gaussKernel,cmap=plt.cm.gray)\n",
        "plt.title('Gaussian Kernel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wWYwHR82MFK"
      },
      "source": [
        "Applying the Gaussian kernel to an image gives the same image smoothed.\n",
        "\n",
        "**TODO**: Play with the values of *sigma* and the kernel size *k* to see the effect on the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8gO_uhTxfu6"
      },
      "source": [
        "#Apply to the original image\n",
        "#If we use a colour image, the kernel is applied to each channel\n",
        "#independently\n",
        "blurred_image = cv2.filter2D(im,-1,gaussKernel)\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(im)\n",
        "plt.title('Original')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(blurred_image)\n",
        "plt.title('Blurred image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoAboPlutFnA"
      },
      "source": [
        "# Shaperning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4KzMxrOtJIb"
      },
      "source": [
        "#Sharpening filter\n",
        "\n",
        "#Average filter: returns the average on a 3x3 neighbourhood\n",
        "average_kernel = np.ones((3,3),np.float32)/9.0\n",
        "\n",
        "#Delta kernel: returns (twice) the value of the pixel\n",
        "delta_kernel = np.array([[0,0,0],\n",
        "\t\t\t\t[0,1,0],\n",
        "\t\t\t\t[0,0,0]],np.float32)\n",
        "\n",
        "\t\n",
        "print(average_kernel)\n",
        "print(delta_kernel)\n",
        "\n",
        "#The sharpening kernel is a combination of the other two\n",
        "#We suubtract the average to twice the value at a pixel\n",
        "sharpening_kernel = 2*delta_kernel - average_kernel\n",
        "\n",
        "print(sharpening_kernel)\n",
        "\n",
        "#If we use a colour image, the kernel is applied to each channel\n",
        "#independently\n",
        "sharpened_image = cv2.filter2D(im,-1,sharpening_kernel)\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.imshow(im)\n",
        "plt.title('Original')\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.imshow(sharpened_image)\n",
        "plt.title('Sharpened image')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}