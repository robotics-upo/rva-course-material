{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3CNLBE2Tz7XmCAp3tKsvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robotics-upo/rva-course-material/blob/master/imageprocessingbasics/filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0f230XxjCmZ"
      },
      "source": [
        "# Linear Filtering in OpenCV\n",
        "\n",
        "In this lab session we will use the following tools:\n",
        "\n",
        "*   **OpenCV**: http://opencv.org\n",
        "*   **Numpy**, for handling multidimensional arrays (like images): https://numpy.org/\n",
        "*   **Matplotlib**, library for visualization in python: https://matplotlib.org/\n",
        "\n",
        "We will use the 4.x version of OpenCV’s API. We will intensively refer to the documentation (https://docs.opencv.org/4.11.0/d6/d00/tutorial_py_root.html)\n",
        "\n",
        "We analyze the **linear filtering** operations in OpenCV and use them to extract features of interest like borders.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYTNL2u9i67O"
      },
      "source": [
        "#OpenCV module\n",
        "import cv2\n",
        "\n",
        "#Numpy module\n",
        "import numpy as np\n",
        "\n",
        "#We can use OpenCV in Colab, but not its functions for creating plots\n",
        "#We use matplotlib for generating plots\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "#We use the library scikit to read images from url\n",
        "#In OpenCV, the function to read from file is cv2.imread\n",
        "from skimage import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvx6yyNajxko"
      },
      "source": [
        "\n",
        "As seen in the slides, one very common region-based operation is filtering.\n",
        "\n",
        "Linear filters operate by convolving a **kernel** with the image.\n",
        "\n",
        "* 2D linear filters, convolutions:\n",
        "  * https://docs.opencv.org/4.11.0/d4/d13/tutorial_py_filtering.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yybQAR_jfCx"
      },
      "source": [
        "im = io.imread('https://robotics.upo.es/~lmercab/rva/background.jpg')\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(im)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9FKoP9woJFQ"
      },
      "source": [
        "# Smoothing filters\n",
        "\n",
        "One filter that is used typically to remove noise is an **smoothing filter**. A smoothing filter averages the region surrounding the pixel of interest.\n",
        "\n",
        "If we want to give more importance to zones closer to a given pixel, typically a Gaussian kernel is used (the Gaussian kernel has many nice properties as well, but we will not see them now).\n",
        "\n",
        "The (isotropic) Gaussian function in 2D (centered in the point $(k/2,k/2$)) is given by:\n",
        "\n",
        "$g(i,j)=\\frac{1}{2 \\pi \\sigma^2}e^{-\\frac{(i-k/2)^2+(j-k/2)^2}{2\\sigma^2}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgJxS0rxoMG7"
      },
      "source": [
        "#Create a Gaussian kernel\n",
        "#Size\n",
        "k=11\n",
        "#Sigma\n",
        "sigma=1.5\n",
        "\n",
        "gaussKernel=np.zeros(shape=(k,k))\n",
        "\n",
        "#Apply the Gaussian 'bell' equation (see above) to determine the value of element\n",
        "#of the kernel.\n",
        "for i in range(k):\n",
        "  for j in range(k):\n",
        "    gaussKernel[i,j] = np.exp(-((i-(k-1)/2)**2+(j-(k-1)/2)**2)/(2*(sigma**2)))\n",
        "\n",
        "#Normalize the kernel (so all element sum 1.0)\n",
        "gaussKernel /= np.sum(gaussKernel)\n",
        "\n",
        "#Show the kernel values\n",
        "print(gaussKernel)\n",
        "\n",
        "#Plot the kernel as a image\n",
        "plt.figure()\n",
        "plt.imshow(gaussKernel,cmap=plt.cm.gray)\n",
        "plt.title('Gaussian Kernel')\n",
        "\n",
        "#Plot the kernel in 3D\n",
        "u = np.arange(0, k, 1)\n",
        "v = np.arange(0, k, 1)\n",
        "U, V = np.meshgrid(u, v)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "# Plot the surface.\n",
        "surf = ax.plot_surface(U, V, gaussKernel,\n",
        "                       linewidth=0, antialiased=False, cmap=cm.coolwarm)\n",
        "ax.set_title('Gaussian Kernel (3D view)')\n",
        "# Add a color bar which maps values to colors.\n",
        "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wWYwHR82MFK"
      },
      "source": [
        "Applying the Gaussian kernel to an image gives the same image smoothed.\n",
        "\n",
        "**TODO**: Play with the values of *sigma* and the kernel size *k* to see the effect on the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8gO_uhTxfu6"
      },
      "source": [
        "#Apply to the original image\n",
        "#If we use a colour image, the kernel is applied to each channel\n",
        "#independently\n",
        "blurred_image = cv2.filter2D(im,-1,gaussKernel)\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(im)\n",
        "plt.title('Original')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(blurred_image)\n",
        "plt.title('Blurred image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoAboPlutFnA"
      },
      "source": [
        "# Shaperning Filters\n",
        "\n",
        "The convolution operation is a linear operation. This means that the sum of several filtered images is the same as the image convolved with the sum of the kernels. This can be used to combine several kernels to obtain the desired effect.\n",
        "\n",
        "For instance, a sharpening effect can be obtained by substracting a delta kernel (that leaves the image intact) and an averaging kernel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4KzMxrOtJIb"
      },
      "source": [
        "#Sharpening filter\n",
        "\n",
        "#Average filter: returns the average on a 3x3 neighbourhood\n",
        "average_kernel = np.ones((3,3),np.float32)/9.0\n",
        "\n",
        "#Delta kernel: returns the value of the pixel\n",
        "delta_kernel = np.array([[0,0,0],\n",
        "\t\t\t\t[0,1,0],\n",
        "\t\t\t\t[0,0,0]],np.float32)\n",
        "\n",
        "\n",
        "print(average_kernel)\n",
        "print(delta_kernel)\n",
        "\n",
        "#The sharpening kernel is a combination of the other two\n",
        "#We subtract the average to twice the value at a pixel\n",
        "sharpening_kernel = 2*delta_kernel - average_kernel\n",
        "\n",
        "print(sharpening_kernel)\n",
        "\n",
        "#If we use a colour image, the kernel is applied to each channel\n",
        "#independently\n",
        "sharpened_image = cv2.filter2D(im,-1,sharpening_kernel)\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.imshow(im)\n",
        "plt.title('Original')\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.imshow(sharpened_image)\n",
        "plt.title('Sharpened image')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7VRdM_Qk7j3"
      },
      "source": [
        "# Edge Detection Filters\n",
        "\n",
        "One important feature in images are their borders. To extract borders, we look for regions in which the *directional derivatives* are high.\n",
        "\n",
        "These derivatives can be extracted using filters, like the **Sobel filters**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju1NtgZ7Ayap"
      },
      "source": [
        "#Sobel kernel for edge detection\n",
        "filter_kernel = np.array([[-1,-2,-1],\n",
        "\t\t\t\t[0,0,0],\n",
        "\t\t\t\t[1,2,1]])\n",
        "\n",
        "print(filter_kernel)\n",
        "\n",
        "#Apply filter over the blue channel. -1 indicates that the pixel type in the output is the same\n",
        "#as the input (in this case, uint8)\n",
        "h_edges = cv2.filter2D(im[:,:,0],-1,filter_kernel)\n",
        "\n",
        "#Type of pixels\n",
        "print(h_edges.dtype)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(h_edges,cmap=plt.cm.gray)\n",
        "plt.title('Filtered')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1VIGhj7A1qN"
      },
      "source": [
        "Two points the we need to take into account:\n",
        "\n",
        "First, now we have to be careful with the types of the images. Filtering operations will lead to outputs that typically are **real numbers**, while the pixels in the original image in this case are coded as `uint8`. If we maintain the same type, we will be loosing information. By including the parameter `cv2.CV_64F` in the call to `filter2D`, the pixels of the output will be stored as `float`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWbdY8rDlL_g"
      },
      "source": [
        "#The problem with the former case is that, as the output is uint8, negative numbers\n",
        "#are truncated to 0. That is edges from bright to dark do not appear\n",
        "#Alternatively, we can store the output as floats\n",
        "h_edges_2 = cv2.filter2D(im[:,:,0],cv2.CV_64F,filter_kernel)\n",
        "\n",
        "#Type of pixels\n",
        "print(h_edges_2.dtype)\n",
        "\n",
        "#Get now the absolute value\n",
        "abs_h_edges64f = np.absolute(h_edges_2)\n",
        "\n",
        "#Check the difference\n",
        "plt.figure()\n",
        "plt.imshow(abs_h_edges64f,cmap=plt.cm.gray)\n",
        "plt.title('Filtered with Sobel Kernel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCOLaekmSFKR"
      },
      "source": [
        "Another **important point**: The Sobel kernel can give high values in noisy regions. Thus, the derivative is typically applied to smoothed images, that eliminate part of the noise, leading to cleaner edge responses.\n",
        "\n",
        "**TODO**: Check the difference, and play with the Gaussian kernel above to change different values of $\\sigma$. We will relate this to the concept of *scale* in future lessons.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1xjk3_ISaBy"
      },
      "source": [
        "h_edges_blurred = cv2.filter2D(blurred_image[:,:,0],cv2.CV_64F,filter_kernel)\n",
        "\n",
        "#Get now the absolute value\n",
        "abs_h_edges64f_blurred = np.absolute(h_edges_blurred)\n",
        "\n",
        "#Check the difference\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(abs_h_edges64f,cmap=plt.cm.gray)\n",
        "plt.title('Filtered with Sobel Kernel')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(abs_h_edges64f_blurred,cmap=plt.cm.gray)\n",
        "plt.title('Filtered with Gaussian and then Sobel Kernel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W3Y0pGFl5u9"
      },
      "source": [
        "The kernels are also `numpy` arrays. By **transposing** the former kernel, we obtain a filter that \"responds\" to vertical edges:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXIVQebalxJ0"
      },
      "source": [
        "#Same as above, but filter with the transpose of the kernel\n",
        "v_edges_2_blurred = cv2.filter2D(blurred_image[:,:,0],cv2.CV_64F,np.transpose(filter_kernel))\n",
        "abs_v_edges64f_blurred = np.absolute(v_edges_2_blurred)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(abs_v_edges64f_blurred,cmap=plt.cm.gray)\n",
        "plt.title('Vertical edges kernel')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzXEQzw2uKLJ"
      },
      "source": [
        "## Homework #1\n",
        "\n",
        "Play with the thresholds and add binary operations to obtain a clean binary edge image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_JEA1tLme1r"
      },
      "source": [
        "#We can add the outputs to obtain an image\n",
        "#with the response of both filters (in this case, the absolute value)\n",
        "abs_edges_64f = abs_v_edges64f_blurred + abs_h_edges64f_blurred\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(abs_edges_64f,cmap=plt.cm.gray)\n",
        "plt.title('Edge response')\n",
        "\n",
        "#Check the values of abs_edges_f64. They not need to be between 0 and 255\n",
        "print('Maximum', np.max(abs_edges_64f))\n",
        "print('Minimum', np.min(abs_edges_64f))\n",
        "\n",
        "\n",
        "#We can apply the threshold operation to extract the stongest responses\n",
        "ret,binary_edges = cv2.threshold(abs_edges_64f,100,255,cv2.THRESH_BINARY)\n",
        "\n",
        "#kernel = np.ones((3,3))\n",
        "#binary_edges = cv2.erode(binary_edges,kernel)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(binary_edges,cmap=plt.cm.gray)\n",
        "plt.title('Binarized edges ')\n",
        "\n",
        "print(binary_edges.dtype)\n",
        "print('Maximum', np.max(binary_edges))\n",
        "print('Minimum', np.min(binary_edges))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L26bUxs4hze"
      },
      "source": [
        "# Contours\n",
        "\n",
        "Given a binary image with objects of interest, we can extract their contours using the OpenCV function `findContours`\n",
        "\n",
        "* https://docs.opencv.org/4.11.0/d3/d05/tutorial_py_table_of_contents_contours.html\n",
        "\n",
        "The function returns a Python list with the countours of all elements in the binary image. Each contour is an array with the pixel coordinates of the points in the contour. The function offers multiple options for dealing with contours. There are **two important parameters**:\n",
        "\n",
        "* **Mode**: how the contours are organized. For instance:\n",
        " * `CV_RETR_EXTERNAL` retrieves only the extreme outer contours.\n",
        " * `CV_RETR_LIST`: retrieves all of the contours without establishing any hierarchical relationships\n",
        "* **Method**: how the contour is extracted. For instance:\n",
        " * `CV_CHAIN_APPROX_NONE` stores absolutely all the contour points.\n",
        " * `CV_CHAIN_APPROX_SIMPLE` compresses horizontal, vertical, and diagonal segments and leaves only their end points.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOIu6d-puyGs"
      },
      "source": [
        "squares = []\n",
        "\n",
        "#findContours require unit8 binary images\n",
        "edges = np.uint8(binary_edges)\n",
        "\n",
        "#Check the parameters of findContours\n",
        "contours, _hierarchy = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "print(len(contours))\n",
        "\n",
        "#Make a copy of the original image to draw over it\n",
        "#This is important. Assignments (A = B) in numpy arrays does not create\n",
        "#a new array, but a new reference to the same allocated data\n",
        "im_draw = im.copy()\n",
        "\n",
        "#We can draw the contours over the image\n",
        "cv2.drawContours(im_draw, contours, -1, (255, 0, 0), 2 )\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(im_draw)\n",
        "plt.title('Extracted contours ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6bGSz8X8nmA"
      },
      "source": [
        "With the contours, then we can do many things. You can compute contour features like length, area, etc:\n",
        "\n",
        "* https://docs.opencv.org/4.11.0/dd/d49/tutorial_py_contour_features.html\n",
        "\n",
        "In the following example, we look for rectangles in the image\n",
        "(adapted from opencv_source/samples/python2/squares.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atHLouxK4nPB"
      },
      "source": [
        "#Function that computes the (absolute value of the) cosine of the angle formed\n",
        "#by 3 consecutive vertices\n",
        "def angle_cos(p0, p1, p2):\n",
        "    d1, d2 = (p0-p1).astype('float'), (p2-p1).astype('float')\n",
        "    return abs( np.dot(d1, d2) / np.sqrt( np.dot(d1, d1)*np.dot(d2, d2) ) )\n",
        "\n",
        "#contours is a Python list for all contours. Each contour is a\n",
        "#numpy array of points\n",
        "for cnt in contours:\n",
        "  #Compute lenght\n",
        "  cnt_len = cv2.arcLength(cnt, True)\n",
        "\n",
        "  #Approximate the contour by a polygon, allowing as error a 2% of the length\n",
        "  cnt = cv2.approxPolyDP(cnt, 0.02*cnt_len, True)\n",
        "\n",
        "  #If the resultant polygon has 4 vertices and is convex it may be a rectangle\n",
        "  #We also set a threshold for the area of the square (to avoid too small ones)\n",
        "  if len(cnt) == 4 and cv2.contourArea(cnt) > 1000 and cv2.isContourConvex(cnt):\n",
        "    #Reshape the array for convenience\n",
        "    #print(cnt.shape)\n",
        "    cnt = cnt.reshape(-1, 2)\n",
        "    #print(cnt.shape)\n",
        "\n",
        "    #Check if the angles of the polygong are close to 90º (cos(90) = 0)\n",
        "    max_cos = np.max([angle_cos( cnt[i], cnt[(i+1) % 4], cnt[(i+2) % 4] ) for i in range(4)])\n",
        "    if max_cos < 0.1:\n",
        "      squares.append(cnt)\n",
        "\n",
        "#Draw resultant contours\n",
        "cv2.drawContours(im_draw, squares, -1, (0, 255, 0), 3 )\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(im_draw)\n",
        "plt.title('Extracted squares ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYN4Aw0TInuk"
      },
      "source": [
        "## Homework #2\n",
        "\n",
        "Using the given image, extract the pixel coordinates of the corners of the black square encompasing the AruCO marker, as well as the area of the white rectangles inside the black square."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqSQyKhGHJcr"
      },
      "source": [
        "#Target image\n",
        "hm2 = io.imread('https://robotics.upo.es/~lmercab/rva/aruco.jpg')\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(hm2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE3FLjCo-QR6"
      },
      "source": [
        "## Homework #3\n",
        "\n",
        "Detect and provide the center pixel coordinates of all **yield signs** in the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWMcUXM_-ZU3"
      },
      "source": [
        "#Target image\n",
        "hm2 = io.imread('https://robotics.upo.es/~lmercab/rva/doble-ceda.jpg')\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(hm2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}