{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "templatematching.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM5lusGV90rQs7uihFEplUX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robotics-upo/rva-course-material/blob/master/imageprocessingbasics/templatematching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-mrQwEMoX10"
      },
      "source": [
        "# Template Matching in OpenCV\n",
        "\n",
        "In this lab session we will use the following tools:\n",
        "\n",
        "*   **OpenCV**: http://opencv.org\n",
        "*   **Numpy**, for handling multidimensional arrays (like images): https://numpy.org/\n",
        "*   **Matplotlib**, library for visualization in python: https://matplotlib.org/\n",
        "\n",
        "We will use the 3.x version of OpenCVâ€™s API. We will intensively refer to the documentation (https://opencv-python-tutroals.readthedocs.io/en/latest/index.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkYUvaEVfTa-"
      },
      "source": [
        "#OpenCV module\n",
        "import cv2\n",
        "\n",
        "#Numpy module\n",
        "import numpy as np\n",
        "\n",
        "#We can use OpenCV in Colab, but not its functions for creating plots\n",
        "#We use matplotlib for generating plots\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#We use the library scikit to read images from url \n",
        "#In OpenCV, the function to read from file is cv2.imread\n",
        "from skimage import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH7NRx_MolEd"
      },
      "source": [
        "One function that we have seen in theory is **template matching**. \n",
        "\n",
        "The objective is to look for a template on an image, and\n",
        "determine the most likely location of the template.\n",
        "\n",
        "For instance, we may want to look, in the following **image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO6lx2DJi9ZB"
      },
      "source": [
        "#Image\n",
        "im = io.imread('https://robotics.upo.es/~lmercab/rva/waldo4.jpg')\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_WvEdQ1pDnz"
      },
      "source": [
        "the next **template**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMNxWHVmj0Dl"
      },
      "source": [
        "#Template\n",
        "temp = io.imread('https://robotics.upo.es/~lmercab/rva/temp.jpg')\n",
        "\n",
        "plt.imshow(temp)\n",
        "\n",
        "#Dimensions of images\n",
        "print('Image', im.shape)\n",
        "print('Template', temp.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VM_GQ3OprkV"
      },
      "source": [
        "OpenCV has a function to look for a pattern on an image:\n",
        "\n",
        "```\n",
        "result = cv2.matchTemplate(image, templ, method [, result [, mask]])\n",
        "```\n",
        "\n",
        "*   http://docs.opencv.org/modules/imgproc/doc/object_detection.html?highlight=matchtemplate#matchtemplate\n",
        "\n",
        "\n",
        "This function returns in result a **similarity map**, in the form of an image. The maximum of this map will indicate where is the pattern located. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9_G2jfqlX9z"
      },
      "source": [
        "#Compute the similarity map\n",
        "sim_map = cv2.matchTemplate(im,temp,cv2.TM_CCOEFF_NORMED)\n",
        "\n",
        "#The returned field is a numpy array of real values\n",
        "print(sim_map.dtype)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(sim_map)\n",
        "plt.colorbar(fraction=0.03)\n",
        "\n",
        "#Check the max and min values\n",
        "print('Maximum', np.max(sim_map))\n",
        "print('Minimum', np.min(sim_map))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YknKzsCZtF3T"
      },
      "source": [
        "To look for the maximum (or minimum) of the previous map, we can use the function:\n",
        "\n",
        "```\n",
        "minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(src [, mask])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abM3Olxdnd7R"
      },
      "source": [
        "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(sim_map)\n",
        "print('Max. pixel:', max_loc)\n",
        "print('Max. value:',max_val)\n",
        "print('Min. pixel:', min_loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc6zkMZEuL0u"
      },
      "source": [
        "OpenCV has several functions to draw on the images. They are quite useful for debugging and to show results.\n",
        "\n",
        "* https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_drawing_functions/py_drawing_functions.html#drawing-functions\n",
        "\n",
        "For instance:\n",
        "\n",
        "```\n",
        "cv2.circle(img, center, radius, color, thickness)\n",
        "```\n",
        "\n",
        "which draws a circle on the image img, at the position center, with radius radius.\n",
        "\n",
        "In the same way, it is possible to draw further figures, as a rectangle:\n",
        "\n",
        "```\n",
        "cv2.rectangle(img, upperleftpoint, lowerrightpoint, color, thickness)\n",
        "```\n",
        "\n",
        "We use them next to show  the result of the former steps "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw5RvzcMuC-1"
      },
      "source": [
        "#Store the height and width of the template:\n",
        "h=temp.shape[0]\n",
        "w=temp.shape[1]\n",
        "\n",
        "#Make a copy of the original image to draw over it\n",
        "#This is important. Assignments (A = B) in numpy arrays does not create \n",
        "#a new array, but a new reference to the same allocated data\n",
        "im_draw = im.copy()\n",
        "\n",
        "#We draw a rectangle of the same size as the template at the maximum location\n",
        "#bottom_right is the location of the bottom right pixel with respect to that\n",
        "#maximum\n",
        "bottom_right = (max_loc[0] + w, max_loc[1] + h)\n",
        "cv2.rectangle(im_draw,max_loc, bottom_right, 255, 2)\n",
        "\n",
        "#We draw a circle at the maximum location\n",
        "cv2.circle(im_draw,max_loc,10,255,2);\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(im_draw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqX4tXz9w_ve"
      },
      "source": [
        "# Homework #1\n",
        "\n",
        "Read about and change and play with the similarity metric considered in the function `matchTemplate` and see the results:\n",
        "\n",
        "*  CV_TM_SQDIFF (in this case the minimum indicates the maximum similarity)\n",
        "*  CV_TM_SQDIFF_NORMED (normalized version)\n",
        "*  CV_TM_CCORR\n",
        "*  CV_TM_CCORR_NORMED\n",
        "*  CV_TM_CCOEFF\n",
        "*  CV_TM_CCOEFF_NORMED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJl5UN8sD08X"
      },
      "source": [
        "# Template matching in multiple scales\n",
        "\n",
        "What happens when the size of the template is different than the image because of the scale? \n",
        "\n",
        "We need to search for the template in multiple scales in the image. For that, we can use image pyramids.\n",
        "\n",
        "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_pyramids/py_pyramids.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Y7fgf5CznN"
      },
      "source": [
        "im = io.imread('https://robotics.upo.es/~lmercab/rva/book-174.jpg')\n",
        "temp = io.imread('https://robotics.upo.es/~lmercab/rva/book_template4.jpg')\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(im)\n",
        "\n",
        "plt.figure(figsize=(0.35,0.35))\n",
        "plt.imshow(temp)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(temp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBLaUcp-h3W1"
      },
      "source": [
        "If we create the similarity map at the original scale, the template will not match"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHy6C3EMDoSg"
      },
      "source": [
        "#Compute the similarity map\n",
        "sim_map = cv2.matchTemplate(im,temp,cv2.TM_CCORR_NORMED)\n",
        "\n",
        "#The returned field is a numpy array of real values\n",
        "print(sim_map.dtype)\n",
        "\n",
        "max_val_scales = [] \n",
        "max_loc_scales = [] \n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(sim_map)\n",
        "plt.colorbar(fraction=0.03)\n",
        "\n",
        "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(sim_map)\n",
        "\n",
        "max_val_scales.append(max_val)\n",
        "max_loc_scales.append(max_loc)\n",
        "\n",
        "print('Max. pixel:', max_loc_scales[0])\n",
        "print('Max. value:',max_val_scales[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyX_OosDlPCb"
      },
      "source": [
        "def drawObject(image,template,max_loc):\n",
        "  #Store the height and width of the template:\n",
        "  h=template.shape[0]\n",
        "  w=template.shape[1]\n",
        "\n",
        "  #We draw a rectangle of the same size as the template at the maximum location\n",
        "  #bottom_right is the location of the bottom right pixel with respect to that\n",
        "  #maximum\n",
        "  bottom_right = (max_loc[0] + w, max_loc[1] + h)\n",
        "  cv2.rectangle(im_draw,max_loc, bottom_right, 255, 2)\n",
        "\n",
        "  #We draw a circle at the maximum location\n",
        "  cv2.circle(im_draw,max_loc,10,255,2); \n",
        "\n",
        "\n",
        "im_draw = im.copy()\n",
        "\n",
        "drawObject(im_draw,temp,max_loc_scales[0])\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(im_draw)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARSEHq6YiFs6"
      },
      "source": [
        "We can use the pyrDown function in OpenCV to generate downscaled versions of the image by octaves. \n",
        "\n",
        "Please notice the scale of the axes in the figures.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZRwSUCgmTLR"
      },
      "source": [
        "#Dowsample image by 2\n",
        "imrgb_2 = cv2.pyrDown(im)\n",
        "#Downsample the former by 2 (so the original by 4)\n",
        "imrgb_4 = cv2.pyrDown(imrgb_2)\n",
        "\n",
        "plt.figure(figsize=(13,13))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(im)\n",
        "plt.title('Original Scale')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(imrgb_2)\n",
        "plt.title('Downsampled 1 octave down')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(imrgb_4)\n",
        "plt.title('Downsampled 2 octaves down')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHFfqmZ6imql"
      },
      "source": [
        "Let's compute the similarity map at those new scales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz1QRzOKoYFx"
      },
      "source": [
        "#Compute the similarity map\n",
        "sim_map = cv2.matchTemplate(imrgb_2,temp,cv2.TM_CCORR_NORMED)\n",
        "\n",
        "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(sim_map)\n",
        "print('Max. pixel:', max_loc)\n",
        "print('Max. value:',max_val)\n",
        "\n",
        "max_val_scales.append(max_val)\n",
        "max_loc_scales.append(max_loc)\n",
        "\n",
        "im_draw = imrgb_2.copy()\n",
        "\n",
        "drawObject(im_draw,temp,max_loc_scales[1])\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(sim_map)\n",
        "plt.colorbar(fraction=0.03)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(im_draw)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEfcZSShMrxx"
      },
      "source": [
        "#Compute the similarity map\n",
        "sim_map = cv2.matchTemplate(imrgb_4,temp,cv2.TM_CCORR_NORMED)\n",
        "\n",
        "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(sim_map)\n",
        "print('Max. pixel:', max_loc)\n",
        "print('Max. value:',max_val)\n",
        "\n",
        "max_val_scales.append(max_val)\n",
        "max_loc_scales.append(max_loc)\n",
        "\n",
        "print(max_loc_scales)\n",
        "\n",
        "im_draw = imrgb_4.copy()\n",
        "\n",
        "drawObject(im_draw,temp,max_loc_scales[2])\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(sim_map)\n",
        "plt.colorbar(fraction=0.03)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(im_draw)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzUm4bCrivlD"
      },
      "source": [
        "If the template is found in one scale, we can estimate the bounding box in the original scale by scaling back the positions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ5TMa2CO8lw"
      },
      "source": [
        "#Show the maximum in the original image. We have to re-scale up\n",
        "\n",
        "p = max_loc_scales[1]\n",
        "\n",
        "im_draw = im.copy()\n",
        "\n",
        "top_left = (2*p[0], 2*p[1])\n",
        "bottom_right = (2*p[0] + 2*temp.shape[1], 2*p[1] + 2*temp.shape[0])\n",
        "cv2.rectangle(im_draw,top_left, bottom_right, 255, 2)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(im_draw)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}